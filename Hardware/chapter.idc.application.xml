<?xml version="1.0" encoding="UTF-8"?>
<chapter>
	<title>瓶颈分析</title>
	
	
	<section>
		<title>pmap/strace</title>
		<screen>
# pmap -d 27970

27970:   /usr/local/httpd-2.2.16/bin/httpd -k restart
Address           Kbytes Mode  Offset           Device    Mapping
0000000000400000     576 r-x-- 0000000000000000 008:00001 httpd
0000000000690000      20 rw--- 0000000000090000 008:00001 httpd
0000000000695000      16 rw--- 0000000000695000 000:00000   [ anon ]
0000000005dda000   14880 rw--- 0000000005dda000 000:00000   [ anon ]
0000000041d2b000       4 ----- 0000000041d2b000 000:00000   [ anon ]
0000000041d2c000   10240 rw--- 0000000041d2c000 000:00000   [ anon ]
00002aaaaaab6000      52 r-x-- 0000000000000000 008:00001 libgcc_s-4.1.2-20080825.so.1
00002aaaaaac3000    2048 ----- 000000000000d000 008:00001 libgcc_s-4.1.2-20080825.so.1
00002aaaaacc3000       4 rw--- 000000000000d000 008:00001 libgcc_s-4.1.2-20080825.so.1
00002aaaaacc4000     268 rw-s- 0000000000000000 000:00009 zero (deleted)
		</screen>
		<para>系统调用</para>
		<screen>
		</screen>
	</section>
	<section>
		<title>web server</title>
		<screen>
		<![CDATA[
假设apache日志格式为：

118.78.199.98 - - [09/Jan/2010:00:59:59 +0800] "GET /Public/Css/index.css HTTP/1.1" 304 - "http://www.a.cn/common/index.php" "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; GTB6.3)"

问题1：在apachelog中找出访问次数最多的10个IP。
awk '{print $1}' apache_log |sort |uniq -c|sort -nr|head
awk 首先将每条日志中的IP抓出来，如日志格式被自定义过，可以 -F 定义分隔符和 print指定列；
sort进行初次排序，为的使相同的记录排列到一起；
upiq -c 合并重复的行，并记录重复次数。
head进行前十名筛选；
sort -nr按照数字进行倒叙排序。
    我参考的命令是：
    显示10条最常用的命令
    sed -e "s/| /\n/g" ~/.bash_history | cut -d ' ' -f 1 | sort | uniq -c | sort -nr | head


问题2：在apache日志中找出访问次数最多的几个分钟。
awk '{print  $4}' apache.log |cut -c 14-18|sort|uniq -c|sort -nr|head
awk 用空格分出来的第四列是[09/Jan/2010:00:59:59；
cut -c 提取14到18个字符
剩下的内容和问题1类似。

问题3：在apache日志中找到访问最多的页面：
awk '{print $11}' apache_log |sed 's/^.*cn\(.*\)\"/\1/g'|sort |uniq -c|sort -rn|head
类似问题1和2，唯一特殊是用sed的替换功能将"http://www.a.cn/common/index.php"替换成括号内的内容："http://www.a.cn（/common/index.php）"


问题4：在apache日志中找出访问次数最多（负载最重）的几个时间段（以分钟为单位），然后在看看这些时间哪几个IP访问的最多？
版本1
#!/bin/bash
# analysis apache access log
# histroy
# caoyameng  version0.1 2010/01/24

if (test -z $1) ;then
 read -p "Specify  logfile:" LOG
else
        LOG=$1
fi

if [ ! -e $LOG ];then
echo "I cann't find apache log file."
exit 0
fi

awk '{print  $4}' $LOG |cut -c 14-18|sort|uniq -c|sort -nr|head  >timelog
for   i in  `awk '{print $2}' timelog`
do

all=`grep $i timelog|awk '{print $1}'`
echo  " $i  $all"
IP=`grep $i $LOG| awk '{print $1}' |sort |uniq -c|sort -nr|head`
echo  "$IP"

done
rm  -f timelog

另一个版本的解决方法，其实就是换了下for的计算方式

#!/bin/bash
# analysis apache access log
# histroy
# caoyameng  version0.2 2010/01/24

if (test -z $1) ;then
 read -p "Specify  logfile:" LOG
else
        LOG=$1
fi

if [ ! -e $LOG ];then
echo "I cann't find apache log file."
exit 0
fi

awk '{print  $4}' $LOG |cut -c 14-18|sort|uniq -c|sort -nr|head  >timelog
for (( i=1; i<=10; i=i+1 ))
do
num=`sed -n "${i}p" timelog|awk '{print $1}'`
time=`sed -n "${i}p" timelog|awk '{print $2}'`
echo  "####The No.$i "
echo  " "
echo  " $time   $num"
echo  " "
full=`grep $time $LOG| awk '{print $1}' |sort |uniq -c|sort -nr|head`
echo  "$full"
echo " "
done
rm  -f timelog
		]]>
		</screen>
	</section>

</chapter>

		

<chapter>
	<title>Analytics</title>
	<para>我们从下面的分析软件反馈的结果，可以用于网站我一些调整，也可能给市场人员一个参考。</para>
</chapter>